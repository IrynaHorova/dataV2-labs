{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Script will Get the list of all tags with its id number and ouput a file at `./data/tag_id.csv`\n",
    "### As of 11/8/2019. There are xxx tags. More information about the API can be found here https://rawg.io/apidocs and its endpoints can be found here https://api.rawg.io/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import os\n",
    "import csv\n",
    "from time import time\n",
    "import concurrent.futures\n",
    "import functools\n",
    "import math\n",
    "from pandas import json_normalize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading\n",
    "#### This function is responsible for requesting pages of tags (20 tags per page) and save as a JSON file in `/data/tag_id/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def threading(start_index, pages_per_worker, urls, downloaded_files, headers):\n",
    "    for url in urls[start_index : start_index + pages_per_worker]:\n",
    "        if url.rsplit(\"?page=\")[-1] in downloaded_files: continue \n",
    "        try:\n",
    "            # Request API\n",
    "            json_data = json.loads(requests.get(url, headers=headers).text)\n",
    "            # Get wanted data\n",
    "            D = {tag[\"id\"]:tag[\"slug\"] for tag in json_data[\"results\"]}\n",
    "            # Save data\n",
    "            page_no = int(url.split(\"page=\")[-1])\n",
    "            with open(fr\"./data/tag_id/{page_no}.json\", \"w\", encoding=\"utf8\") as f:\n",
    "                json.dump(D, f)\n",
    "        except:\n",
    "            print(f\"Error with {url}\")\n",
    "    # Verbose notification\n",
    "    print(f\"Done from {page_no - N} to {page_no}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create folder if not existed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/tag_id/'):\n",
    "    os.makedirs('data/tag_id/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following codes apply concurrent programming to speed up the progress. 50 workers are running at the same time. Each of the workers will individually make a request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make the first request to get the total amount of pages to get\n",
    "headers = { 'User-Agent': 'App Name: Education purpose',}\n",
    "json_data = json.loads(requests.get(r\"https://api.rawg.io/api/tags\", headers=headers).text)\n",
    "no_of_pages = math.ceil(json_data[\"count\"]/20)\n",
    "\n",
    "# Set up number of workers\n",
    "max_workers = 50\n",
    "pages_per_worker = int(no_of_pages/max_workers)\n",
    "start_index = range(0, no_of_pages, pages_per_worker)\n",
    "\n",
    "# Make urls\n",
    "url = \"https://api.rawg.io/api/tags?page=1\"\n",
    "#ky = '&key=13961a85724f47818f318bebae6b82e1'\n",
    "urls = [url[:-1] + str(i)  for i in range(1, no_of_pages + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 23.523433446884155\n"
     ]
    }
   ],
   "source": [
    "# Skipped downloaded files\n",
    "downloaded_files = {file.split(\".\",1)[0] for file in os.listdir(\"data/tag_id/\")}\n",
    "\n",
    "# Time\n",
    "t0=time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    temp = functools.partial(threading,\n",
    "                             pages_per_worker=pages_per_worker,\n",
    "                             urls=urls,\n",
    "                             downloaded_files=downloaded_files,\n",
    "                             headers=headers,\n",
    "                            )\n",
    "    executor.map(temp, start_index)\n",
    "print(f\"Time taken: {time()-t0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load each JSON file in `data/tag_id/` and write to a CSV file which i saved at `data/tag_id.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/tag_id.csv\", \"w\") as f:\n",
    "    csv_file = csv.writer(f, lineterminator=\"\\n\")\n",
    "    for file in os.listdir(\"./data/tag_id/\"):\n",
    "        try:\n",
    "            json_data = json.load(open(f\"./data/tag_id/{file}\", \"r\"))\n",
    "        except:\n",
    "            print(file)\n",
    "        for tag_id, tag_name in json_data.items():\n",
    "            csv_file.writerow([tag_id, tag_name])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
