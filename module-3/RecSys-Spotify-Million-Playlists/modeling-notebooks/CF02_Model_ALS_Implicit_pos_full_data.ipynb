{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS Implicit Collaborative Filtering - pos ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluation.ipynb\n",
      "DCG = 0.5\n",
      "IDCG = 1.0\n",
      "nDCG = 0.5\n"
     ]
    }
   ],
   "source": [
    "from evaluation import DCG\n",
    "from evaluation import nDCG\n",
    "from evaluation import R_Precision\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import implicit\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendation and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# FIND SIMILAR ITEMS\n",
    "#---------------------\n",
    "\n",
    "def similar_items(seed_track, top_n):\n",
    "    \"\"\"\n",
    "    input: track_uri\n",
    "    output: top_n recommended track_uris\n",
    "    \"\"\"\n",
    "    track_id = D_track_id[seed_track] \n",
    "    n_similar =  top_n\n",
    "\n",
    "    # Use implicit to get similar items.\n",
    "    similar = model.similar_items(track_id, n_similar)\n",
    "    \n",
    "    similar_i = []\n",
    "    \n",
    "    # Print the names of our most similar artists\n",
    "    for item in similar:\n",
    "        idx, score = item\n",
    "        track_uri = data.track_uri.loc[data.track_uri_id == idx].iloc[0]\n",
    "        #print(data.track_uri.loc[data.track_uri_id == idx].iloc[0], D_desc[track_uri])\n",
    "        similar_i.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "    return similar_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------\n",
    "# FIND SIMILAR ITEMS WITH DESCRIPTION\n",
    "#-------------------------------------\n",
    "\n",
    "def similar_items_with_description(seed_track, top_n):\n",
    "    \"\"\"\n",
    "    input: track_uri\n",
    "    output: top_n recommended track_uris with description as dictionary\n",
    "    \"\"\"\n",
    "    print('CF ALS pos - first track returned is the seed track')\n",
    "    \n",
    "    track_id = D_track_id[seed_track] \n",
    "    n_similar =  top_n+1\n",
    "\n",
    "    # Use implicit to get similar items.\n",
    "    similar = model.similar_items(track_id, n_similar)\n",
    "    \n",
    "    similar_i = {}\n",
    "    \n",
    "    # Print the names of our most similar artists\n",
    "    for item in similar:\n",
    "        idx, score = item\n",
    "        track_uri = data.track_uri.loc[data.track_uri_id == idx].iloc[0]\n",
    "        similar_i[track_uri] = D_desc[track_uri]\n",
    "        #print(data.track_uri.loc[data.track_uri_id == idx].iloc[0], D_desc[track_uri])\n",
    "        #similar_i.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "    return list(similar_i.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# CREATE USER RECOMMENDATIONS\n",
    "#------------------------------\n",
    "\n",
    "def create_recs(pid,N):\n",
    "    \"\"\"\n",
    "    returna list\n",
    "    \"\"\"\n",
    "    \n",
    "    pid_id = pid\n",
    "\n",
    "    # Use the implicit recommender.\n",
    "    recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "\n",
    "    tracks = []\n",
    "    scores = []\n",
    "    desc = []\n",
    "\n",
    "    # Get artist names from ids\n",
    "    for item in recommended:\n",
    "        idx, score = item\n",
    "        tracks.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "        scores.append(score)\n",
    "        #desc.append(D_desc[data.track_uri.loc[data.track_uri_id == idx].iloc[0]])\n",
    "\n",
    "    # Create a dataframe of artist names and scores\n",
    "    #recommendations = pd.DataFrame({'track_uris': tracks, 'score': scores})\n",
    "\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# CREATE SEED TRACKS FROM A PID\n",
    "#----------------------------------------------\n",
    "\n",
    "def get_seed_tracks(pid):\n",
    "    pid_id = pid\n",
    "    print(f'Seed tracks from pid {pid_id}')\n",
    "    # Use the implicit recommender.\n",
    "    I = {}\n",
    "    for el in data[data.pid == pid_id].track_uri.unique():\n",
    "        I[el] = D_desc[el]\n",
    "    \n",
    "#     recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "    \n",
    "#     R = {}\n",
    "\n",
    "#     for item in recommended:\n",
    "#         idx, score = item\n",
    "#         R[data.track_uri.loc[data.track_uri_id == idx].iloc[0]] = D_desc[data.track_uri.loc[data.track_uri_id == idx].iloc[0]]\n",
    "    \n",
    "    return list(I.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# CREATE USER RECOMMENDATIONS WITH DESCRIPTION\n",
    "#----------------------------------------------\n",
    "\n",
    "def create_recs_with_description(pid,N):\n",
    "    pid_id = pid\n",
    "    print(f'Recommendations for {pid_id}')\n",
    "#     # Use the implicit recommender.\n",
    "#     I = {}\n",
    "#     for el in data[data.pid == pid_id].track_uri.unique():\n",
    "#         I[el] = D_desc[el]\n",
    "    \n",
    "    recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "    \n",
    "    R = {}\n",
    "\n",
    "    for item in recommended:\n",
    "        idx, score = item\n",
    "        R[data.track_uri.loc[data.track_uri_id == idx].iloc[0]] = D_desc[data.track_uri.loc[data.track_uri_id == idx].iloc[0]]\n",
    "    \n",
    "    return list(R.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# CREATE USER RECOMMENDATIONS WITH DICTIONARY OUTPUT\n",
    "#---------------------------------------------------\n",
    "def create_recs_dictionary_output(pid,N):\n",
    "    \"\"\"\n",
    "    input: pid\n",
    "    output: reccomendation dictionary {track_uri: score}\n",
    "    \"\"\"\n",
    "    \n",
    "    pid_id = pid\n",
    "\n",
    "    # Use the implicit recommender.\n",
    "    recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "\n",
    "    rec_tracks = {}\n",
    "\n",
    "    # Get artist names from ids\n",
    "    for item in recommended:\n",
    "        idx, score = item\n",
    "        rec_tracks[D_track_id_to_uri[idx]] = score\n",
    "#         tracks.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "#         scores.append(score)\n",
    "        #desc.append(D_desc[data.track_uri.loc[data.track_uri_id == idx].iloc[0]])\n",
    "\n",
    "    # Create a dataframe of artist names and scores\n",
    "    #recommendations = pd.DataFrame({'track_uris': tracks, 'score': scores})\n",
    "\n",
    "    return rec_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------\n",
    "# GET RECOMMENDATIONS AND EVALUATE\n",
    "#----------------------------------\n",
    "\n",
    "def als_predict_and_evaluate_top_n(pid, top_n=100):\n",
    "    \"\"\"\n",
    "    return\n",
    "    (1) top_n predicted: track_ids\n",
    "    (2) ground_truth : track_ids in the hold_out\n",
    "    (3) R_Prec\n",
    "    (4) NDGC\n",
    "    \n",
    "    \"\"\"\n",
    "    L_pred = list(create_recs_dictionary_output(pid,top_n).keys())\n",
    "    \n",
    "    ground_truth = ev_set_arr[ev_set_arr[:,0]==pid][:,1]\n",
    "    \n",
    "    R_Prec = R_Precision(L_pred[:len(ground_truth)],ground_truth)\n",
    "    \n",
    "    res = [int(el in ground_truth) for el in L_pred]\n",
    "    \n",
    "    NDCG = nDCG(res)[1]\n",
    "    \n",
    "    return L_pred, ground_truth, R_Prec, NDCG, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------\n",
    "# SAVE R-PRECISION AND NDCG BY PID\n",
    "#-----------------------------------\n",
    "\n",
    "def save_als_res_k_n(n = 10, top_n=20):\n",
    "    \"\"\"\n",
    "    k = number of factors\n",
    "    n= number of random lists to predict\n",
    "    \"\"\"\n",
    "    time0=time()\n",
    "    RES={}\n",
    "    ep = random.sample(evaluation_pids,n)\n",
    "    for i,pid in enumerate(ep):\n",
    "        predictions=als_predict_and_evaluate_top_n(pid,top_n)\n",
    "        RES[pid] = [predictions[2], predictions[3]]\n",
    "        if i % 500 ==0:\n",
    "            print(i)\n",
    "            print(time()-time0)\n",
    "    df = pd.DataFrame(RES).transpose().reset_index()\n",
    "    df.columns=['pid','R-Precision','nDCG']\n",
    "    df['rating'] = 'pos'\n",
    "    df['model'] = f'ALS'\n",
    "    df.to_csv(f'../evaluation/ALS_pos_topn_{top_n}_{n}.csv', index = None)\n",
    "    print(time()-time0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_track_artist(name, entity):\n",
    "    S = []\n",
    "    if entity == 'track':\n",
    "        for k, v in D_desc.items():\n",
    "            if v[0].lower().find(name.lower()) !=-1:\n",
    "                S.append([k, v])\n",
    "    if entity == 'artist':\n",
    "        for k, v in D_desc.items():\n",
    "            if v[1].lower().find(name.lower()) !=-1:\n",
    "                S.append([k, v])     \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data-processed/full-data/pid-track-pos-rating-train-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data like we did before\n",
    "raw_data = pd.read_csv(file_path)\n",
    "# raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns = ['pid', 'track_uri', 'rating']\n",
    "data = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numeric user_id and artist_id column\n",
    "data['pid'] = data['pid'].astype(\"category\")\n",
    "data['track_uri'] = data['track_uri'].astype(\"category\")\n",
    "data['pid_id'] = data['pid'].cat.codes\n",
    "data['track_uri_id'] = data['track_uri'].cat.codes\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_track_id = data.groupby('track_uri')['track_uri_id'].min().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_track_id_to_uri = {}\n",
    "for k,v in D_track_id.items():\n",
    "    D_track_id_to_uri[v] = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The implicit library expects data as a item-user matrix so we\n",
    "# create two matricies, one for fitting the model (item-user) \n",
    "# and one for recommendations (user-item)\n",
    "sparse_item_user = sparse.csr_matrix((data['rating'].astype(float), (data['track_uri_id'], data['pid_id'])))\n",
    "sparse_user_item = sparse.csr_matrix((data['rating'].astype(float), (data['pid_id'], data['track_uri_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.1, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confidence by multiplying it by our alpha value.\n",
    "alpha_val = 15\n",
    "data_conf = (sparse_item_user * alpha_val).astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bebc23c7ffb4bb09d12121a6c2ec7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dictionary with tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lose Control (feat. Ciara & Fat Man Scoop)', 'Missy Elliott', 'The Cookbook']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('../data-processed/full-data/track_descriptions.json') as json_file:\n",
    "    D_desc = json.load(json_file)\n",
    "    \n",
    "D_desc['spotify:track:0UaMYEvWZi0ZqiDOoHU3YI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set = pd.read_csv('../data-processed/full-data/evaluation-pids-ground-truth.csv')\n",
    "evaluation_set.head()\n",
    "\n",
    "ev_set = evaluation_set[evaluation_set['hold_out'] == 1][['pid','track_uri','hold_out']]\n",
    "ev_set = ev_set[ev_set.isnull()==False]\n",
    "\n",
    "ev_set_arr = ev_set.to_numpy()\n",
    "\n",
    "evaluation_pids = list(ev_set.pid.unique())\n",
    "\n",
    "# ev_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `~~~~~~~~~~~~~~~~~~~~~~~~~~~ DEMO TIME~~~~~~~~~~~~~~~~~~~~~~~~~~~`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"tenor.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for track or artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spotify:track:4NnWuGQujzWUEg0uZokO5M',\n",
       "  ['Just Like Heaven', 'The Cure', 'Kiss Me, Kiss Me, Kiss Me']],\n",
       " ['spotify:track:4QlzkaRHtU8gAdwqjWmO8n',\n",
       "  [\"Friday I'm In Love\", 'The Cure', 'Wish']],\n",
       " ['spotify:track:0X5C4WjQNubRysTkHOubz3',\n",
       "  ['Lovesong', 'The Cure', 'Disintegration']],\n",
       " ['spotify:track:1QFh8OH1e78dGd3VyJZCAC',\n",
       "  [\"Boys Don't Cry\", 'The Cure', 'Three Imaginary Boys']],\n",
       " ['spotify:track:0T6kwiueP62ten2KLLmQS4',\n",
       "  ['A Forest', 'The Cure', 'Seventeen Seconds']]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_or_artist = 'the cure'\n",
    "entity = 'artist'\n",
    "results_to_print = 5\n",
    "search_track_artist(track_or_artist, entity)[0:results_to_print]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF ALS pos - first track returned is the seed track\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[\"Friday I'm In Love\", 'The Cure', 'Wish'],\n",
       " ['Just Like Heaven', 'The Cure', 'Kiss Me, Kiss Me, Kiss Me'],\n",
       " ['Blister in the Sun - 2002 Remastered Version',\n",
       "  'Violent Femmes',\n",
       "  'Violent Femmes'],\n",
       " ['Love It When You Call', 'The Feeling', 'Twelve Stops and Home'],\n",
       " ['I Melt With You', 'Modern English', 'Pillow Lips'],\n",
       " ['There She Goes', \"The La's\", \"The La's\"],\n",
       " [\"What's Up?\", '4 Non Blondes', 'Bigger, Better, Faster, More !'],\n",
       " ['Everybody Wants To Rule The World',\n",
       "  'Tears For Fears',\n",
       "  'Songs From The Big Chair'],\n",
       " [\"Don't Dream It's Over\", 'Crowded House', 'Crowded House'],\n",
       " ['Lovesong', 'The Cure', 'Disintegration'],\n",
       " [\"Spinnin' N Reelin'\", 'Creed Bratton', \"The 80's\"],\n",
       " ['I Will Survive', 'Gloria Gaynor', 'Big Hits'],\n",
       " ['Dreams', 'The Cranberries', \"Everybody Else Is Doing It, So Why Can't We?\"],\n",
       " ['Alright', 'Supergrass', 'I Should Coco'],\n",
       " [\"Don't You (Forget About Me)\", 'Simple Minds', 'Once Upon A Time'],\n",
       " [\"It's the End of the World As We Know It (And I Feel Fine)\",\n",
       "  'R.E.M.',\n",
       "  'Document (R.E.M. No. 5)']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_items_with_description('spotify:track:4QlzkaRHtU8gAdwqjWmO8n',15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a playlist continuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed tracks from pid 248033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[\"Keep On Movin'\", 'King Tuff', 'King Tuff'],\n",
       " ['Rat House', 'Shannon and The Clams', 'Dreams in the Rat House'],\n",
       " ['Lovers Lane', 'Hunx & His Punx', 'Too Young To Be In Love'],\n",
       " ['Bad Boy', 'Hunx & His Punx', 'Too Young To Be In Love'],\n",
       " ['Boomerenga', 'Guantanamo Baywatch', 'Chest Crawl'],\n",
       " ['Pina Colada', 'Guantanamo Baywatch', 'Chest Crawl'],\n",
       " ['Frizzela', 'Guantanamo Baywatch', 'Chest Crawl'],\n",
       " ['We Came with Dottie', 'Guantanamo Baywatch', 'Chest Crawl'],\n",
       " ['Diana', 'Guantanamo Baywatch', 'Chest Crawl'],\n",
       " ['Massage My Taj Mahal', 'Guantanamo Baywatch', 'Chest Crawl'],\n",
       " ['If I Could Count', 'Shannon and The Clams', 'Dreams in the Rat House'],\n",
       " ['Heads or Tails', 'Shannon and The Clams', 'Dreams in the Rat House'],\n",
       " ['Into a Dream', 'Shannon and The Clams', 'Dreams in the Rat House'],\n",
       " ['I Know', 'Shannon and The Clams', 'Dreams in the Rat House'],\n",
       " ['Candy, Forget About Me',\n",
       "  'Shannon and The Clams',\n",
       "  'Dreams in the Rat House'],\n",
       " ['Crimson Wave', 'Tacocat', 'NVM'],\n",
       " ['Spring Break-Up', 'Tacocat', 'Take Me to Your Dealer'],\n",
       " ['Sk8 Witch', 'Tacocat', \"Woman's Day\"],\n",
       " ['Sk8 Or Die', 'Tacocat', \"Woman's Day\"],\n",
       " ['Walking in the Dark', 'Guantanamo Baywatch', 'Chest Crawl'],\n",
       " ['Follow Me', 'The Coathangers', 'Suck My Shirt'],\n",
       " ['Springfield Cannonball', 'The Coathangers', 'Suck My Shirt'],\n",
       " ['Bloodstains',\n",
       "  'Agent Orange',\n",
       "  'Greatest & Latest: This, That-N-The Other Thing'],\n",
       " ['Everything Turns Grey',\n",
       "  'Agent Orange',\n",
       "  'Greatest & Latest: This, That-N-The Other Thing'],\n",
       " ['Alcohol', 'Gang Green', 'Another Wasted Night'],\n",
       " ['Skate To Hell', 'Gang Green', 'Another Wasted Night'],\n",
       " ['Bored Out Of My Brains',\n",
       "  'Personal and The Pizzas',\n",
       "  'Diet, Crime & Delinquency']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = random.sample(evaluation_pids,1)[0]\n",
    "get_seed_tracks(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 248033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['So Good At Being in Trouble', 'Unknown Mortal Orchestra', 'II'],\n",
       " ['Salad Days', 'Mac Demarco', 'Salad Days'],\n",
       " ['Age Of Consent - 2015 Remastered Version',\n",
       "  'New Order',\n",
       "  'Power, Corruption & Lies'],\n",
       " ['Archie, Marry Me', 'Alvvays', 'Alvvays'],\n",
       " ['Red Eyes', 'The War On Drugs', 'Lost in the Dream'],\n",
       " ['Ode To Viceroy', 'Mac Demarco', '2'],\n",
       " ['Space Song', 'Beach House', 'Depression Cherry'],\n",
       " ['Let It Happen', 'Tame Impala', 'Currents'],\n",
       " ['Myth', 'Beach House', 'Bloom'],\n",
       " ['Chamber Of Reflection', 'Mac Demarco', 'Salad Days'],\n",
       " ['Multi-Love', 'Unknown Mortal Orchestra', 'Multi-Love'],\n",
       " ['Oblivion', 'Grimes', 'Visions'],\n",
       " [\"'Cause I'm A Man\", 'Tame Impala', 'Currents'],\n",
       " ['Seasons (Waiting On You)', 'Future Islands', 'Singles'],\n",
       " [\"It's Real\", 'Real Estate', 'Days'],\n",
       " ['Eventually', 'Tame Impala', 'Currents'],\n",
       " ['Feeling Myself', 'Nicki Minaj', 'The Pinkprint'],\n",
       " ['Baby (Bonus Track)', 'Ariel Pink', 'Mature Themes'],\n",
       " ['Pretty Pimpin', 'Kurt Vile', \"b'lieve i'm goin down...\"],\n",
       " ['No Woman', 'Whitney', 'Light Upon the Lake']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_recs_with_description(inp, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = save_als_res_k_n(10000,500)\n",
    "# df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
