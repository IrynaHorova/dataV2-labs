{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conten Based filtering using audio features, album_uri and artist_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluation.ipynb\n",
      "DCG = 0.5\n",
      "IDCG = 1.0\n",
      "nDCG = 0.5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sps\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from category_encoders import TargetEncoder\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#own functions\n",
    "from evaluation import DCG\n",
    "from evaluation import nDCG\n",
    "from evaluation import R_Precision\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to look up similar items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lose Control (feat. Ciara & Fat Man Scoop)', 'Missy Elliott', 'The Cookbook']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data-processed/full-data/track_descriptions.json') as json_file:\n",
    "    D_desc = json.load(json_file)\n",
    "    \n",
    "D_desc['spotify:track:0UaMYEvWZi0ZqiDOoHU3YI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_items(track_uri, top_n, similarity_matrix):\n",
    "    #print('seed track is not included')\n",
    "    D_rec={}\n",
    "    #time0 = time()\n",
    "    idx = D_track_uri_to_id[track_uri]\n",
    "    similarity_array = cosine_similarity(similarity_matrix[idx:idx+1,:], similarity_matrix)\n",
    "    recc_tracks = np.fliplr(similarity_array.argsort())\n",
    "    for el in recc_tracks[0][1:top_n+1]:\n",
    "        D_rec[D_track_id_to_uri[el]]=similarity_array[0][el]\n",
    "    #print(f'{time()-time0:0.2f}sec')\n",
    "    return D_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_items_with_description(track_uri, top_n, similarity_matrix):\n",
    "    print('CB audio features - first tracks returned is the seed track')\n",
    "    D_rec={}\n",
    "    time0 = time()\n",
    "    idx = D_track_uri_to_id[track_uri]\n",
    "    similarity_array = cosine_similarity(similarity_matrix[idx:idx+1,:], similarity_matrix)\n",
    "    recc_tracks = np.fliplr(similarity_array.argsort())\n",
    "    for el in recc_tracks[0][0:top_n+1]:\n",
    "        D_rec[D_track_id_to_uri[el]]=D_desc[D_track_id_to_uri[el]]\n",
    "    print(f'{time()-time0:0.2f}sec')\n",
    "    return list(D_rec.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_items_with_description_external(track_uri, top_n):\n",
    "    print('CB audio features - first tracks returned is the seed track')\n",
    "    D_rec={}\n",
    "    time0 = time()\n",
    "    idx = D_track_uri_to_id[track_uri]\n",
    "    similarity_array = cosine_similarity(X_transformed[idx:idx+1,:], X_transformed)\n",
    "    recc_tracks = np.fliplr(similarity_array.argsort())\n",
    "    for el in recc_tracks[0][0:top_n+1]:\n",
    "        D_rec[D_track_id_to_uri[el]]=D_desc[D_track_id_to_uri[el]]\n",
    "    print(f'{time()-time0:0.2f}sec')\n",
    "    return list(D_rec.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def predict_and_evaluate_top_n(pid,top_n):\n",
    "    \"\"\"\n",
    "    return\n",
    "    (1) top_n predicted track_ids\n",
    "    (2) ground_truth : track_ids in the hold_out\n",
    "    (3) R_Prec\n",
    "    \n",
    "    \"\"\"\n",
    "    train_array_track_ids = track_id_array[M[pid].toarray()[0].astype(bool)]\n",
    "    \n",
    "    D_pred={}\n",
    "    \n",
    "    topn_n_by_track = int(top_n/len(train_array_track_ids))*2\n",
    "    \n",
    "    for el in train_array_track_ids:\n",
    "        D_pred.update(similar_items(D_track_id_to_uri[el],topn_n_by_track,X_transformed))\n",
    "    \n",
    "    D_pred = dict(sorted(D_pred.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    ground_truth = ev_set_arr[ev_set_arr[:,0]==pid][:,2]\n",
    "    L_pred = list(D_pred.keys())[:top_n]\n",
    "    R_Prec = R_Precision(L_pred[:len(ground_truth)],ground_truth)\n",
    "    res = [int(el in list(ground_truth)) for el in L_pred]\n",
    "    NDCG = nDCG(res)[1]\n",
    "    return L_pred, ground_truth, R_Prec, NDCG, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation, PCA and merging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv('../data-processed/transformation-matrices/cb_df_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged = df_merged.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged.to_csv('../data-processed/transformation-matrices/cb_df_merged.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = np.asarray(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tenor.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_items_with_description('spotify:track:3ZOEytgrvLwQaqXreDs2Jx',10,X_transformed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
