{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS Implicit Collaborative Filtering - binary ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluation.ipynb\n",
      "DCG = 0.5\n",
      "IDCG = 1.0\n",
      "nDCG = 0.5\n"
     ]
    }
   ],
   "source": [
    "from evaluation import DCG\n",
    "from evaluation import nDCG\n",
    "from evaluation import R_Precision\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import implicit\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendation and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# FIND SIMILAR ITEMS\n",
    "#---------------------\n",
    "\n",
    "def similar_items(seed_track, top_n):\n",
    "    \"\"\"\n",
    "    input: track_uri\n",
    "    output: top_n recommended track_uris\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    track_id = D_track_id[seed_track] \n",
    "    n_similar =  top_n\n",
    "\n",
    "    # Use implicit to get similar items.\n",
    "    similar = model.similar_items(track_id, n_similar)\n",
    "    \n",
    "    similar_i = []\n",
    "    \n",
    "    # Print the names of our most similar artists\n",
    "    for item in similar:\n",
    "        idx, score = item\n",
    "        track_uri = data.track_uri.loc[data.track_uri_id == idx].iloc[0]\n",
    "        #print(data.track_uri.loc[data.track_uri_id == idx].iloc[0], D_desc[track_uri])\n",
    "        similar_i.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "    return similar_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------\n",
    "# FIND SIMILAR ITEMS WITH DESCRIPTION\n",
    "#-------------------------------------\n",
    "\n",
    "def similar_items_with_description(seed_track, top_n):\n",
    "    \"\"\"\n",
    "    input: track_uri\n",
    "    output: top_n recommended track_uris with description as dictionary\n",
    "    \"\"\"\n",
    "    print('CF ALS binary - first track returned is the seed track')\n",
    "    \n",
    "    track_id = D_track_id[seed_track] \n",
    "    n_similar =  top_n+1\n",
    "\n",
    "    # Use implicit to get similar items.\n",
    "    similar = model.similar_items(track_id, n_similar)\n",
    "    \n",
    "    similar_i = {}\n",
    "    \n",
    "    # Print the names of our most similar artists\n",
    "    for item in similar:\n",
    "        idx, score = item\n",
    "        track_uri = data.track_uri.loc[data.track_uri_id == idx].iloc[0]\n",
    "        similar_i[track_uri] = D_desc[track_uri]\n",
    "        #print(data.track_uri.loc[data.track_uri_id == idx].iloc[0], D_desc[track_uri])\n",
    "        #similar_i.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "    return list(similar_i.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# CREATE USER RECOMMENDATIONS\n",
    "#------------------------------\n",
    "\n",
    "# Create recommendations for user with id 2025\n",
    "def create_recs(pid,N):\n",
    "    \"\"\"\n",
    "    returna list\n",
    "    \"\"\"\n",
    "    \n",
    "    pid_id = pid\n",
    "\n",
    "    # Use the implicit recommender.\n",
    "    recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "\n",
    "    tracks = []\n",
    "    scores = []\n",
    "    desc = []\n",
    "\n",
    "    # Get artist names from ids\n",
    "    for item in recommended:\n",
    "        idx, score = item\n",
    "        tracks.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "        scores.append(score)\n",
    "        #desc.append(D_desc[data.track_uri.loc[data.track_uri_id == idx].iloc[0]])\n",
    "\n",
    "    # Create a dataframe of artist names and scores\n",
    "    #recommendations = pd.DataFrame({'track_uris': tracks, 'score': scores})\n",
    "\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# CREATE USER RECOMMENDATIONS WITH DESCRIPTION\n",
    "#----------------------------------------------\n",
    "\n",
    "def create_recs_with_description(pid,N):\n",
    "    pid_id = pid\n",
    "\n",
    "    # Use the implicit recommender.\n",
    "    I = {}\n",
    "    for el in data[data.pid == pid_id].track_uri.unique():\n",
    "        I[el] = D_desc[el]\n",
    "    \n",
    "    recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "    \n",
    "    R = {}\n",
    "\n",
    "    for item in recommended:\n",
    "        idx, score = item\n",
    "        R[data.track_uri.loc[data.track_uri_id == idx].iloc[0]] = D_desc[data.track_uri.loc[data.track_uri_id == idx].iloc[0]]\n",
    "    \n",
    "    return list(I.values()), list(R.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# CREATE USER RECOMMENDATIONS WITH DICTIONARY OUTPUT\n",
    "#---------------------------------------------------\n",
    "def create_recs_dictionary_output(pid,N):\n",
    "    \"\"\"\n",
    "    input: pid\n",
    "    output: reccomendation dictionary {track_uri: score}\n",
    "    \"\"\"\n",
    "    \n",
    "    pid_id = pid\n",
    "\n",
    "    # Use the implicit recommender.\n",
    "    recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "\n",
    "    rec_tracks = {}\n",
    "\n",
    "    # Get artist names from ids\n",
    "    for item in recommended:\n",
    "        idx, score = item\n",
    "        rec_tracks[D_track_id_to_uri[idx]] = score\n",
    "#         tracks.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "#         scores.append(score)\n",
    "        #desc.append(D_desc[data.track_uri.loc[data.track_uri_id == idx].iloc[0]])\n",
    "\n",
    "    # Create a dataframe of artist names and scores\n",
    "    #recommendations = pd.DataFrame({'track_uris': tracks, 'score': scores})\n",
    "\n",
    "    return rec_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------\n",
    "# GET RECOMMENDATIONS AND EVALUATE\n",
    "#----------------------------------\n",
    "\n",
    "def als_predict_and_evaluate_top_n(pid, top_n=100):\n",
    "    \"\"\"\n",
    "    return\n",
    "    (1) top_n predicted: track_ids\n",
    "    (2) ground_truth : track_ids in the hold_out\n",
    "    (3) R_Prec\n",
    "    (4) NDGC\n",
    "    \n",
    "    \"\"\"\n",
    "    L_pred = list(create_recs_dictionary_output(pid,top_n).keys())\n",
    "    \n",
    "    ground_truth = ev_set_arr[ev_set_arr[:,0]==pid][:,1]\n",
    "    \n",
    "    R_Prec = R_Precision(L_pred[:len(ground_truth)],ground_truth)\n",
    "    \n",
    "    res = [int(el in ground_truth) for el in L_pred]\n",
    "    \n",
    "    NDCG = nDCG(res)[1]\n",
    "    \n",
    "    return L_pred, ground_truth, R_Prec, NDCG, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------\n",
    "# SAVE R-PRECISION AND NDCG BY PID\n",
    "#-----------------------------------\n",
    "\n",
    "def save_als_res_k_n(n = 10, top_n=20):\n",
    "    \"\"\"\n",
    "    k = number of factors\n",
    "    n= number of random lists to predict\n",
    "    \"\"\"\n",
    "    time0=time()\n",
    "    RES={}\n",
    "    ep = random.sample(evaluation_pids,n)\n",
    "    for i,pid in enumerate(ep):\n",
    "        predictions=als_predict_and_evaluate_top_n(pid,top_n)\n",
    "        RES[pid] = [predictions[2], predictions[3]]\n",
    "        if i % 500 ==0:\n",
    "            print(i)\n",
    "            print(time()-time0)\n",
    "#     RES['rating'] = 'binary'\n",
    "#     RES['Model'] = 'ALS_Implicit'\n",
    "#     with open(f'../data-processed/evaluation/ALS_Implicit_binary{n}.json', 'w') as fp:\n",
    "#         json.dump(dict, fp)\n",
    "    df = pd.DataFrame(RES).transpose().reset_index()\n",
    "    df.columns=['pid','R-Precision','nDCG']\n",
    "    df['rating'] = 'binary'\n",
    "    df['model'] = f'ALS'\n",
    "    df.to_csv(f'../evaluation/ALS_binary_topn_{top_n}_{n}.csv', index = None)\n",
    "    print(time()-time0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_track_artist(name, entity):\n",
    "    S = []\n",
    "    if entity == 'track':\n",
    "        for k, v in D_desc.items():\n",
    "            if v[0].lower().find(name.lower()) !=-1:\n",
    "                S.append([k, v])\n",
    "    if entity == 'artist':\n",
    "        for k, v in D_desc.items():\n",
    "            if v[1].lower().find(name.lower()) !=-1:\n",
    "                S.append([k, v])     \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data-processed/full-data/pid-track-binary-rating-train-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data like we did before\n",
    "raw_data = pd.read_csv(file_path)\n",
    "# raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns = ['pid', 'track_uri', 'rating']\n",
    "data = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numeric user_id and artist_id column\n",
    "data['pid'] = data['pid'].astype(\"category\")\n",
    "data['track_uri'] = data['track_uri'].astype(\"category\")\n",
    "data['pid_id'] = data['pid'].cat.codes\n",
    "data['track_uri_id'] = data['track_uri'].cat.codes\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_track_id = data.groupby('track_uri')['track_uri_id'].min().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_track_id_to_uri = {}\n",
    "for k,v in D_track_id.items():\n",
    "    D_track_id_to_uri[v] = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The implicit library expects data as a item-user matrix so we\n",
    "# create two matricies, one for fitting the model (item-user) \n",
    "# and one for recommendations (user-item)\n",
    "sparse_item_user = sparse.csr_matrix((data['rating'].astype(float), (data['track_uri_id'], data['pid_id'])))\n",
    "sparse_user_item = sparse.csr_matrix((data['rating'].astype(float), (data['pid_id'], data['track_uri_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.1, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confidence by multiplying it by our alpha value.\n",
    "alpha_val = 15\n",
    "data_conf = (sparse_item_user * alpha_val).astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6036ae5abb864df091aaad2b0023210e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dictionary with tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lose Control (feat. Ciara & Fat Man Scoop)', 'Missy Elliott', 'The Cookbook']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('../data-processed/full-data/track_descriptions.json') as json_file:\n",
    "    D_desc = json.load(json_file)\n",
    "    \n",
    "D_desc['spotify:track:0UaMYEvWZi0ZqiDOoHU3YI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tenor.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spotify:track:00rKXZwgzFSgIvliePgd9t', ['John Lennon', 'SCH', 'A7']],\n",
       " ['spotify:track:50354a8iMLx8Hw9fDfM0Ff',\n",
       "  ['John Lennon (feat. Spark Master Tape)',\n",
       "   'Kush Kelz',\n",
       "   'Very Fresh 2: Audio Overload']],\n",
       " ['spotify:track:3Tpa9mWs2OlNNvA3WZWZJ7',\n",
       "  ['Imagine - Originally Released by John Lennon',\n",
       "   'The Musicmakers',\n",
       "   \"Mega 70's - 80's, Vol. 2\"]],\n",
       " ['spotify:track:63nzKFA5L5COyhUz7f6PCf',\n",
       "  ['John Lennon', 'The Coasts', 'The Coasts']],\n",
       " ['spotify:track:1IjMikg2WOcwZIdfcIZeMi',\n",
       "  ['John Lennon', 'The Underachievers', 'It Happened In Flatbush (Mixtape)']]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_or_artist = 'john lennon'\n",
    "#entity 'track' or 'name'\n",
    "entity = 'track'\n",
    "results_to_print = 5\n",
    "search_track_artist(track_or_artist, entity)[0:results_to_print]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF ALS binary - first track returned is the seed track\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Personal Jesus', 'Depeche Mode', 'Violator'],\n",
       " ['Enjoy The Silence - Single Mix', 'Depeche Mode', 'Enjoy The Silence'],\n",
       " ['Little Girls', 'Oingo Boingo', 'Only A Lad'],\n",
       " ['Only A Lad', 'Oingo Boingo', 'Only A Lad'],\n",
       " ['Suicide Blonde', 'INXS', 'X'],\n",
       " ['Policy of Truth - Remastered', 'Depeche Mode', 'Violator (Remastered)'],\n",
       " ['E=MC2', 'Big Audio Dynamite', 'This Is Big Audio Dynamite'],\n",
       " ['Never Let Me Down Again - Tsangarides Mix',\n",
       "  'Depeche Mode',\n",
       "  'Never Let Me Down Again'],\n",
       " ['Good Times',\n",
       "  'INXS with Jimmy Barnes',\n",
       "  'Shine Like It Does The Anthology [1979-1997]'],\n",
       " ['Fight', 'The Cure', 'Kiss Me, Kiss Me, Kiss Me'],\n",
       " ['Private Idaho', \"The B-52's\", 'Wild Planet'],\n",
       " ['One Step Beyond', 'Madness', 'One Step Beyond...'],\n",
       " ['I Love A Man In Uniform', 'Gang Of Four', 'Return The Gift'],\n",
       " ['But Not Tonight', 'Depeche Mode', 'Black Celebration (Remastered)'],\n",
       " ['Mayor Of Simpleton - 2001 - Remaster', 'XTC', 'Oranges & Lemons'],\n",
       " [\"Don't Change\", 'INXS', 'Shabooh Shoobah']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_items_with_description('spotify:track:4P9iHeHiwzZAqvQCdoLkGg',15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a playlist continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Ignition - Remix', 'R. Kelly', 'Chocolate Factory'],\n",
       " ['Single Ladies (Put a Ring on It)',\n",
       "  'Beyoncé',\n",
       "  'I AM...SASHA FIERCE - Platinum Edition'],\n",
       " ['Untitled (How Does It Feel)', \"D'Angelo\", 'The Best So Far'],\n",
       " ['U Got It Bad', 'Usher', '8701'],\n",
       " [\"You Don't Know My Name\", 'Alicia Keys', 'The Diary Of Alicia Keys'],\n",
       " ['Love Of My Life (An Ode To Hip Hop) - Longer Album Version',\n",
       "  'Erykah Badu',\n",
       "  'Go! Common Classics'],\n",
       " ['Be Without You', 'Mary J. Blige', 'The Breakthrough'],\n",
       " ['Thrift Shop (feat. Wanz)',\n",
       "  'Macklemore & Ryan Lewis',\n",
       "  'The Heist [Deluxe Edition]'],\n",
       " ['No Scrubs', 'TLC', 'Fanmail'],\n",
       " ['Regulate', 'Warren G', 'Regulate… G Funk Era']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Input')\n",
    "inp = 491004\n",
    "create_recs_with_description(inp, 20)[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Pony', 'Ginuwine', 'R&B: From Doo-Wop To Hip-Hop'],\n",
       " ['No Diggity', 'Blackstreet', 'Another Level'],\n",
       " ['Dilemma', 'Nelly', 'Nellyville'],\n",
       " ['Let Me Love You', 'Mario', 'Turning Point'],\n",
       " ['Suga Suga', 'Baby Bash', \"Tha Smokin' Nephew\"],\n",
       " ['Say My Name', \"Destiny's Child\", \"The Writing's On The Wall\"],\n",
       " ['Yeah!', 'Usher', 'Confessions'],\n",
       " ['My Boo', 'Usher', 'Confessions'],\n",
       " ['Ride Wit Me', 'Nelly', 'Country Grammar'],\n",
       " ['Hot In Herre', 'Nelly', 'Nellyville'],\n",
       " [\"It Wasn't Me\", 'Shaggy', 'Hot Shot'],\n",
       " ['Crazy In Love', 'Beyoncé', 'Dangerously In Love (Alben für die Ewigkeit)'],\n",
       " [\"Bump n' Grind\", 'R. Kelly', '12 Play'],\n",
       " ['Always On Time', 'Ja Rule', 'Pain Is Love'],\n",
       " ['In Da Club', '50 Cent', \"Get Rich Or Die Tryin'\"],\n",
       " ['Hypnotize - 2014 Remastered Version',\n",
       "  'The Notorious B.I.G.',\n",
       "  'Life After Death (Remastered Edition)'],\n",
       " ['One, Two Step', 'Ciara', 'Goodies'],\n",
       " ['This Is How We Do It', 'Montell Jordan', 'This Is How We Do It'],\n",
       " ['Ms. Jackson', 'OutKast', 'Stankonia'],\n",
       " ['Candy Shop', '50 Cent', 'The Massacre']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('output')\n",
    "create_recs_with_description(inp, 20)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation_set = pd.read_csv('../data-processed/full-data/evaluation-pids-ground-truth.csv')\n",
    "# evaluation_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ev_set = evaluation_set[evaluation_set['hold_out'] == 1][['pid','track_uri','hold_out']]\n",
    "# ev_set = ev_set[ev_set.isnull()==False]\n",
    "\n",
    "# ev_set_arr = ev_set.to_numpy()\n",
    "\n",
    "# evaluation_pids = list(ev_set.pid.unique())\n",
    "\n",
    "# # ev_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = save_als_res_k_n(10000,500)\n",
    "# df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
